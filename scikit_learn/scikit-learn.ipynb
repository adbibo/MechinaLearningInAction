{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "# url with dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# download the file\n",
    "raw_data = urllib.urlopen(url)\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "# separate the data from the target attributes\n",
    "X = dataset[:, 0:7]\n",
    "y = dataset[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# scale the data attributes\n",
    "scaled_X = preprocessing.scale(X)\n",
    "\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ..., -0.69289057,\n         0.20401277,  0.46849198],\n       [-0.84488505, -1.12339636, -0.16054575, ..., -0.69289057,\n        -0.68442195, -0.36506078],\n       [ 1.23388019,  1.94372388, -0.26394125, ..., -0.69289057,\n        -1.10325546,  0.60439732],\n       ..., \n       [ 0.3429808 ,  0.00330087,  0.14964075, ...,  0.27959377,\n        -0.73518964, -0.68519336],\n       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.69289057,\n        -0.24020459, -0.37110101],\n       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.69289057,\n        -0.20212881, -0.47378505]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11986381  0.26539435  0.12385869  0.09124154  0.08194818  0.17826198\n  0.13943146]\n"
     ]
    }
   ],
   "source": [
    "#  特征选择\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\nRESULT\n             precision    recall  f1-score   support\n\n        0.0       0.79      0.89      0.84       500\n        1.0       0.74      0.55      0.63       268\n\navg / total       0.77      0.77      0.77       768\n\nCONFUSION MATRIX\n[[447  53]\n [120 148]]\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print('MODEL')\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print('RESULT')\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('CONFUSION MATRIX')\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\nGaussianNB(priors=None)\nRESULT\n             precision    recall  f1-score   support\n\n        0.0       0.80      0.86      0.83       500\n        1.0       0.69      0.60      0.64       268\n\navg / total       0.76      0.77      0.76       768\n\nCONFUSION MATRIX\n[[429  71]\n [108 160]]\n"
     ]
    }
   ],
   "source": [
    "# 朴素贝叶斯\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print('MODEL')\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print('RESULT')\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('CONFUSION MATRIX')\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\n             precision    recall  f1-score   support\n\n        0.0       0.82      0.90      0.86       500\n        1.0       0.77      0.63      0.69       268\n\navg / total       0.80      0.80      0.80       768\n\n[[448  52]\n [ 98 170]]\n"
     ]
    }
   ],
   "source": [
    "# k近邻\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\n             precision    recall  f1-score   support\n\n        0.0       1.00      1.00      1.00       500\n        1.0       1.00      1.00      1.00       268\n\navg / total       1.00      1.00      1.00       768\n\n[[500   0]\n [  0 268]]\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n             precision    recall  f1-score   support\n\n        0.0       1.00      1.00      1.00       500\n        1.0       1.00      1.00      1.00       268\n\navg / total       1.00      1.00      1.00       768\n\n[[500   0]\n [  0 268]]\n"
     ]
    }
   ],
   "source": [
    "# 支持向量机\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n         1.00000e-04,   0.00000e+00])},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n0.282118955686\n1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n/usr/local/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 如何优化算法参数\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001),\n          fit_params={}, iid=True, n_iter=100, n_jobs=1,\n          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10a7d6a90>},\n          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n          scoring=None, verbose=0)\n0.282118791758\n0.993919031391\n"
     ]
    }
   ],
   "source": [
    "# 随机参数选择\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X, y)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
